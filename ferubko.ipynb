{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import RegressorMixin\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import warnings \n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  subprocess\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "the number of columns changed from 328 to 173 at row 2; use `usecols` to select a subset and avoid this error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train_all \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mloadtxt(\u001b[39m'\u001b[39;49m\u001b[39mtrain_X_05.txt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m y_train_all \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mloadtxt(\u001b[39m'\u001b[39m\u001b[39mtrain_y_05.txt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m X_test_all \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mloadtxt(\u001b[39m'\u001b[39m\u001b[39mtest_X_05.txt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/npyio.py:1356\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1353\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(delimiter, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m   1354\u001b[0m     delimiter \u001b[39m=\u001b[39m delimiter\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1356\u001b[0m arr \u001b[39m=\u001b[39m _read(fname, dtype\u001b[39m=\u001b[39;49mdtype, comment\u001b[39m=\u001b[39;49mcomment, delimiter\u001b[39m=\u001b[39;49mdelimiter,\n\u001b[1;32m   1357\u001b[0m             converters\u001b[39m=\u001b[39;49mconverters, skiplines\u001b[39m=\u001b[39;49mskiprows, usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[1;32m   1358\u001b[0m             unpack\u001b[39m=\u001b[39;49munpack, ndmin\u001b[39m=\u001b[39;49mndmin, encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   1359\u001b[0m             max_rows\u001b[39m=\u001b[39;49mmax_rows, quote\u001b[39m=\u001b[39;49mquotechar)\n\u001b[1;32m   1361\u001b[0m \u001b[39mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/npyio.py:999\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m    996\u001b[0m     data \u001b[39m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[1;32m    998\u001b[0m \u001b[39mif\u001b[39;00m read_dtype_via_object_chunks \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 999\u001b[0m     arr \u001b[39m=\u001b[39m _load_from_filelike(\n\u001b[1;32m   1000\u001b[0m         data, delimiter\u001b[39m=\u001b[39;49mdelimiter, comment\u001b[39m=\u001b[39;49mcomment, quote\u001b[39m=\u001b[39;49mquote,\n\u001b[1;32m   1001\u001b[0m         imaginary_unit\u001b[39m=\u001b[39;49mimaginary_unit,\n\u001b[1;32m   1002\u001b[0m         usecols\u001b[39m=\u001b[39;49musecols, skiplines\u001b[39m=\u001b[39;49mskiplines, max_rows\u001b[39m=\u001b[39;49mmax_rows,\n\u001b[1;32m   1003\u001b[0m         converters\u001b[39m=\u001b[39;49mconverters, dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1004\u001b[0m         encoding\u001b[39m=\u001b[39;49mencoding, filelike\u001b[39m=\u001b[39;49mfilelike,\n\u001b[1;32m   1005\u001b[0m         byte_converters\u001b[39m=\u001b[39;49mbyte_converters)\n\u001b[1;32m   1007\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1008\u001b[0m     \u001b[39m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m     \u001b[39m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m     \u001b[39m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[39m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     \u001b[39mif\u001b[39;00m filelike:\n",
      "\u001b[0;31mValueError\u001b[0m: the number of columns changed from 328 to 173 at row 2; use `usecols` to select a subset and avoid this error"
     ]
    }
   ],
   "source": [
    "X_train_all = np.loadtxt('train_X_05.txt')\n",
    "y_train_all = np.loadtxt('train_y_05.txt')\n",
    "X_test_all = np.loadtxt('test_X_05.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_opener(name:str)->list:\n",
    "    with open(name) as f:\n",
    "        array=[]\n",
    "        k=0\n",
    "        for line in f.readlines():\n",
    "            if k%2==0:\n",
    "                lis=line.rstrip('\\n').split(\" \")\n",
    "            if k%2==1:\n",
    "                tt=line.rstrip('\\n').split(\" \")\n",
    "                midl=lis[-1]+tt[0]\n",
    "                lis[-1]=midl\n",
    "                tt.pop(0)\n",
    "                lis=lis+tt\n",
    "                array.append(lis)\n",
    "            k+=1\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all=custom_opener('train_X_05.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('5.371264437873712883e-02',\n",
       " '6.351061916933915530e-01',\n",
       " '8.237333696923794246e-01',\n",
       " '7.158032956323917562e-01')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all[0][0],X_train_all[0][-1],X_train_all[0][328],X_train_all[0][327]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
