{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Студенческий модуль\n",
    "\n",
    "Этот набор кода выполнит за Вас тяжёлую работу по считыванию файлов заданий и расчёту регрессионных моделей, оставив Вам самую лёгкую часть: выбор гиперпараметров и интерпретацию результатов. Запускайте ячейки в том порядке, в котором они записаны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если следующие строки выполняются с ошибками, проверяйте, как Вы ставили sklearn / NumPy / Matplotlib.\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пожалуйста, положите выданные Вам файлы рядом с этим файлом и укажите ниже их имена:\n",
    "X_train = np.loadtxt('train_X_00.txt')\n",
    "y_train = np.loadtxt('train_y_00.txt')\n",
    "X_test = np.loadtxt('test_X_00.txt')\n",
    "# Если при выполнении этой ячейки происходит OSError, убедитесь, что файлы лежат в той же папке,\n",
    "# а также что Вы вводите их имена правильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Попробуем нарисовать все спектры, чтобы посмотреть, с каким набором данных мы имеем дело\n",
    "plt.plot(X_train.T); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод главных компонент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним анализ главных компонент, разложив данную нам матрицу независимых переменных: $$ \\mathbf{X} \\approx \\mathbf T \\mathbf{P}^\\top $$\n",
    "\n",
    "Поскольку главные компоненты полностью аддитивны, нам достаточно начать с большого их количества, а потом отбросить лишние.\n",
    "\n",
    "При этом будем обращать внимание на график значений сингулярных чисел $\\sigma_j$, которые получаются при сингулярном разложении исходной матрицы $ \\mathbf X \\approx \\mathbf U \\operatorname{diag}(\\sigma_1, \\dots, \\sigma_n) \\mathbf{V}^\\top $, а также на долю дисперсии, объясняемой каждым ($j$-ым) компонентом, $||\\mathbf{t}_j \\mathbf{p}^\\top_j||^2 = \\sigma_j^2$ от суммарной объяснённой дисперсии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теоретически, максимальное возможное количество компонентов равно наименьшей\n",
    "# из размерностей матрицы спектров, но мы начнём с меньшего их количества.\n",
    "max_ncomp = 16\n",
    "pc = PCA(n_components = max_ncomp).fit(X_train)\n",
    "plt.plot(pc.singular_values_)\n",
    "plt.title('Сингулярные числа')\n",
    "plt.show()\n",
    "plt.plot(pc.explained_variance_ratio_)\n",
    "plt.title('Доля объяснённой дисперсии')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В следующей ячейке рассмотрите график нагрузок $\\mathbf{v}_j$, попробуйте различные количества главных компонент и выберите, по-Вашему, наболее подходящее. Полезные, содержащие информацию главные компоненты будут иметь форму спектральных пиков, а лишние - содержать шум:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# При проведении анализа на главные компоненты я выбираю ... компонент:\n",
    "# (замените 1 на натуральное число)\n",
    "PCA_comps = 1\n",
    "plt.plot(pc.components_[0:PCA_comps,:].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проекция на латентные структуры\n",
    "\n",
    "Перейдём к задаче предсказания неизвестных концентраций. Здесь мы будем использовать модель ПЛС-1, которая предсказывает неизвестные компоненты по одному. Можно будет увидеть, как для различных столбцов предсказываемой матрицы $\\mathbf Y$ оптимальное количество различается.\n",
    "\n",
    "Для этого обучим серию ПЛС-моделей с разным количеством компонент и выберем то, где модель не начинает врать при перекрёстной проверке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рассчитаем среднеквадратическую ошибку при перекрёстной проверке \n",
    "# индивидуально для каждого компонента\n",
    "cv = [\n",
    "    GridSearchCV(\n",
    "        PLSRegression(scale = False),\n",
    "        {'n_components': list(range(1, max_ncomp+1))},\n",
    "        scoring = 'neg_root_mean_squared_error',\n",
    "        return_train_score = True\n",
    "    ).fit(X_train, y_train[:,i])\n",
    "    for i in range(y_train.shape[1])\n",
    "]\n",
    "# Извлечём результаты и сохраним их в виде матриц\n",
    "ncomps = np.array([\n",
    "    [p['n_components'] for p in v.cv_results_['params']] for v in cv\n",
    "]).T\n",
    "RMSEP = np.array([\n",
    "    -v.cv_results_['mean_train_score'] for v in cv\n",
    "]).T\n",
    "RMSECV = np.array([\n",
    "    -v.cv_results_['mean_test_score'] for v in cv\n",
    "]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1); plt.plot(ncomps, RMSEP);  plt.title('Ошибка предсказания\\nна обучающем наборе')\n",
    "plt.subplot(1, 2, 2); plt.plot(ncomps, RMSECV); plt.title('Ошибка предсказания\\nпри перекрёстной проверке')\n",
    "plt.legend(list(range(1, y_train.shape[1]+1))); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для столбцов [1, 2, 3, 4, 5] я выбираю ... компонент:\n",
    "# Замените 1 на число компонент (натуральное).\n",
    "n_comps = (1, 1, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модели с выбранными количествами компонент, а также нарисуем графики весов PLS (матрицы $\\mathbf{W}$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(len(n_comps)):\n",
    "    m = PLSRegression(\n",
    "        n_components = n_comps[i], scale = False\n",
    "    ).fit(X_train, y_train[:,i])\n",
    "    models.append(m)\n",
    "    plt.plot(m.x_weights_)\n",
    "    plt.title('Веса ПЛС-модели ${\\\\bf w}_j$\\nдля компонента №%d' % (i+1))\n",
    "    plt.show()\n",
    "    plt.plot(m.coef_)\n",
    "    plt.title('Коэффициенты регрессии ${\\\\bf \\\\beta}_j$\\nдля компонента №%d' % (i+1))\n",
    "    plt.show()\n",
    "    \n",
    "predictions = []\n",
    "for i in range(len(n_comps)):\n",
    "    predictions.append(models[i].predict(X_test)[:,0])\n",
    "\n",
    "np.savetxt('y_test.txt', np.array(predictions).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если Вы дошли до этого момента, у Вас должен был получиться файл с предсказанными концентрациями, `y_test.txt`. Отправьте его на <mailto:ikrylov@laser.chem.msu.ru>. Туда же пришлите графики матриц весов и объяснения, почему Вы считаете, что данные количества компонент являются оптимальными.\n",
    "\n",
    "Если что-то не получается, пожалуйста, обращайтесь на тот же адрес, я отвечу."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
